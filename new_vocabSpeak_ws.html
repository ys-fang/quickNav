<!DOCTYPE html>
<html lang="zh-Hant">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è‹±æ–‡å–®å­—ç™¼éŸ³ç·´ç¿’ (Web Speech API)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
    <style>
        body { 
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
        }
        .feedback { 
            min-height: 60px; /* Adjusted min-height for feedback area */
            transition: all 0.3s ease-in-out;
        }
        #recognitionResult {
            min-height: 3em;
        }
        /* Custom focus rings for better visibility */
        input:focus, button:focus {
            outline: 2px solid transparent;
            outline-offset: 2px;
            box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.5); /* Tailwind's blue-500 equivalent */
        }
        /* Styling for word list buttons */
        .word-button {
            transition: background-color 0.2s ease-in-out, transform 0.1s ease-in-out;
        }
        .word-button:hover {
            transform: translateY(-1px);
        }
        .word-button:active {
            transform: translateY(0px);
        }
    </style>
</head>
<body class="bg-gradient-to-br from-sky-100 to-indigo-100 flex flex-col items-center justify-center min-h-screen p-4 text-gray-800">
    <div class="bg-white p-6 md:p-8 rounded-xl shadow-2xl w-full max-w-lg transform transition-all duration-500">
        <header class="mb-6 text-center">
            <h1 class="text-3xl md:text-4xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-sky-500 to-indigo-600">
                ç™¼éŸ³ç·´ç¿’åŠ©æ‰‹
            </h1>
            <p class="text-sm text-gray-500 mt-1">ç·´ç¿’æ‚¨çš„è‹±æ–‡å–®å­—ç™¼éŸ³</p>
        </header>

        <div class="mb-5">
            <label for="targetWord" class="block text-sm font-medium text-gray-700 mb-1">ç›®æ¨™å–®å­—:</label>
            <div class="flex items-center space-x-2">
                <input type="text" id="targetWord" value="medal" class="flex-grow mt-1 block w-full rounded-lg border-gray-300 shadow-sm focus:border-sky-500 focus:ring-sky-500 sm:text-base p-2.5">
                <button id="playTargetWord" title="æ’­æ”¾ç›®æ¨™å–®å­—" class="p-2.5 bg-sky-500 text-white rounded-lg hover:bg-sky-600 focus:outline-none focus:ring-2 focus:ring-sky-500 focus:ring-offset-2 transition-colors">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" d="M19.114 5.636a9 9 0 0 1 0 12.728M16.463 8.288a5.25 5.25 0 0 1 0 7.424M6.75 8.25l4.72-4.72a.75.75 0 0 1 1.28.53v15.88a.75.75 0 0 1-1.28.53l-4.72-4.72H4.51c-.88 0-1.704-.507-1.938-1.354A9.01 9.01 0 0 1 2.25 12c0-.83.112-1.633.322-2.396C2.806 8.756 3.63 8.25 4.51 8.25H6.75Z" /></svg>
                </button>
            </div>
        </div>

        <div class="space-y-3 mb-5">
            <button id="startRecordingButton" class="w-full bg-green-500 text-white font-semibold py-3 px-4 rounded-lg hover:bg-green-600 focus:outline-none focus:ring-2 focus:ring-green-500 focus:ring-offset-2 transition-colors flex items-center justify-center text-base">
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 18.75a6 6 0 0 0 6-6v-1.5m-6 7.5a6 6 0 0 1-6-6v-1.5m6 7.5v3.75m-3.75 0h7.5M12 15.75a3 3 0 0 1-3-3V4.5a3 3 0 1 1 6 0v8.25a3 3 0 0 1-3 3Z" /></svg>
                é–‹å§‹éŒ„éŸ³
            </button>
            <button id="stopRecordingButton" class="w-full bg-red-500 text-white font-semibold py-3 px-4 rounded-lg hover:bg-red-600 focus:outline-none focus:ring-2 focus:ring-red-500 focus:ring-offset-2 transition-colors hidden flex items-center justify-center text-base">
                 <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M5.25 7.5A2.25 2.25 0 0 1 7.5 5.25h9a2.25 2.25 0 0 1 2.25 2.25v9a2.25 2.25 0 0 1-2.25 2.25h-9a2.25 2.25 0 0 1-2.25-2.25v-9Z" /></svg>
                åœæ­¢éŒ„éŸ³
            </button>
        </div>

        <div class="mt-5 p-4 bg-gray-50 rounded-lg shadow-inner">
            <h2 class="text-lg font-medium text-gray-700 mb-1">è¾¨è­˜çµæœ:</h2>
            <p id="recognitionResult" class="text-gray-600 p-2 border border-gray-200 rounded-md bg-white"></p>
        </div>

        <div class="mt-4">
            <h2 class="text-lg font-medium text-gray-700 mb-1">å›é¥‹:</h2>
            <div id="feedback" class="feedback p-3 rounded-md text-base border border-transparent"></div>
        </div>
        <div id="audioPlayerContainer" class="mt-3"></div>
        <div class="mt-3">
            <button id="recognizeAudioButton" class="w-full bg-sky-500 text-white font-semibold py-3 px-4 rounded-lg hover:bg-sky-600 focus:outline-none focus:ring-2 focus:ring-sky-500 focus:ring-offset-2 transition-colors hidden flex items-center justify-center text-base">
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-6 h-6 mr-2">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607zM10.5 7.5v6m3-3h-6" />
                </svg>
                è¾¨è­˜æ­¤éŒ„éŸ³
            </button>
        </div>

        <div id="wordListContainer" class="mt-6 pt-4 border-t border-gray-200">
             <h3 class="text-base font-semibold text-gray-700 mb-3">è©¦è©¦çœ‹é€™äº›å–®å­—:</h3>
             <div id="wordListButtons" class="flex flex-wrap gap-2">
                <!-- Example words will be populated by JS -->
             </div>
        </div>
    </div>

    <footer class="text-center mt-8 mb-4 text-xs text-gray-500">
        <p>ä½¿ç”¨ Web Speech API | å–®å­—èªéŸ³è¾¨è­˜ä»æœ‰èª¤å·®ï¼Œè­˜åˆ¥çµæœåƒ…ä¾›å­¸ç¿’åƒè€ƒ</p>
    </footer>

    <script>
        // ====== Web Speech API ç›¸é—œ ======
        // const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition; // Will be removed
        // let recognition = null; // Will be removed
        // ===================================

        // ====== Azure Speech SDK placeholder (replace with your actual key and region) ======
        const AZURE_SPEECH_KEY = "YOUR_AZURE_SPEECH_KEY";
        const AZURE_SPEECH_REGION = "YOUR_AZURE_REGION";
        // =================================================================================

        // ====== MediaRecorder ç›¸é—œ ======
        let mediaRecorder = null;
        let audioChunks = [];
        let audioBlob = null;
        // ===================================

        document.addEventListener('DOMContentLoaded', () => {
            const targetWordInput = document.getElementById('targetWord');
            const playTargetWordButton = document.getElementById('playTargetWord');
            const startRecordingButton = document.getElementById('startRecordingButton'); // Updated ID
            const stopRecordingButton = document.getElementById('stopRecordingButton');   // Updated ID
            const recognizeAudioButton = document.getElementById('recognizeAudioButton'); // New button
            const recognitionResultP = document.getElementById('recognitionResult');
            const feedbackDiv = document.getElementById('feedback');
            const wordListButtonsDiv = document.getElementById('wordListButtons');
            const audioPlayerContainer = document.getElementById('audioPlayerContainer');

            // let countdownInterval = null; // To be removed or repurposed if needed for recording time limit
            let isRecognizing = false; // This might be repurposed to isRecordingOrProcessing
            // let countdownDiv = null; // To be removed

            let currentTargetWord = targetWordInput.value.trim().toLowerCase();

            // åˆå§‹åŒ– Web Speech API - This section will be removed/replaced by Azure SDK logic
            // if (SpeechRecognition) { ... }
            // else { ... }


            // æ–°å¢å€’æ•¸UI - This function and its calls will be removed
            // function showCountdown(seconds) { ... }
            // function updateCountdown(seconds) { ... }
            // function hideCountdown() { ... }


            targetWordInput.addEventListener('input', () => {
                currentTargetWord = targetWordInput.value.trim().toLowerCase();
                feedbackDiv.innerHTML = '';
                feedbackDiv.className = 'feedback p-3 rounded-md text-base border border-transparent';
                recognitionResultP.textContent = '';
                clearAudioPlayer();
            });

            // ä¿ç•™ TTS
            const speechSynthesis = window.speechSynthesis;
            if (!speechSynthesis) {
                const noTTSWarning = document.createElement('p');
                noTTSWarning.className = 'text-yellow-600 bg-yellow-100 border-yellow-500 border p-3 rounded-md mb-2';
                noTTSWarning.textContent = 'æ‚¨çš„ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³åˆæˆï¼Œéƒ¨åˆ†æ’­æ”¾åŠŸèƒ½å¯èƒ½ç„¡æ³•ä½¿ç”¨ã€‚';
                targetWordInput.parentElement.parentElement.insertBefore(noTTSWarning, targetWordInput.parentElement);
                if(playTargetWordButton) playTargetWordButton.disabled = true;
                if(playTargetWordButton) playTargetWordButton.classList.add('opacity-50', 'cursor-not-allowed');
            }

            // Expanded and categorized confusing pairs
            const confusingPairs = {
                "medal": ["meadow", "metal", "middle", "meddle"],
                "meadow": ["medal"],
                "affect": ["effect"],
                "effect": ["affect"],
                "desert": ["dessert"], // desert (n. /ËˆdÉ›zÉ™rt/), desert (v. /dÉªËˆzÉœËrt/)
                "dessert": ["desert"], // /dÉªËˆzÉœËrt/
                "accept": ["except", "expect"],
                "except": ["accept", "expect"],
                "advice": ["advise"], // /É™dËˆvaÉªs/ (n.)
                "advise": ["advice"], // /É™dËˆvaÉªz/ (v.)
                "weather": ["whether", "wether"],
                "whether": ["weather", "wether"],
                "lead": ["led"],      // lead (v. /liËd/), lead (n. /lÉ›d/)
                "led": ["lead"],      // /lÉ›d/
                "read": ["red"],      // read (pres. /riËd/), read (past /rÉ›d/)
                "red": ["read"],      // /rÉ›d/
                "live": ["leave"],    // live (v. /lÉªv/), live (adj. /laÉªv/)
                "leave": ["live"],    // /liËv/
                "lose": ["loose"],    // /luËz/
                "loose": ["lose"],    // /luËs/
                "principal": ["principle"],
                "principle": ["principal"],
                "quiet": ["quite", "quit"],
                "quite": ["quiet", "quit"],
                "then": ["than"],
                "than": ["then"],
                "their": ["there", "they're"],
                "there": ["their", "they're"],
                "they're": ["their", "there"],
                "to": ["too", "two"],
                "too": ["to", "two"],
                "two": ["to", "too"],
                "allowed": ["aloud"],
                "aloud": ["allowed"],
                "sell": ["cell"],
                "cell": ["sell"]
            };

            const exampleWords = [
                { word: "medal", tip: "çç‰Œ" }, { word: "meadow", tip: "è‰åœ°" },
                { word: "affect", tip: "å½±éŸ¿ (v)" }, { word: "effect", tip: "æ•ˆæœ (n)" },
                { word: "desert", tip: "æ²™æ¼  (n)" }, { word: "dessert", tip: "ç”œé» (n)" },
                { word: "accept", tip: "æ¥å— (v)" }, { word: "except", tip: "é™¤äº† (prep)" },
                { word: "advice", tip: "å¿ å‘Š (n)" }, { word: "advise", tip: "å‹¸å‘Š (v)" },
                { word: "weather", tip: "å¤©æ°£ (n)" }, { word: "whether", tip: "æ˜¯å¦ (conj)" },
                { word: "live", tip: "/lÉªv/ å±…ä½ (v)"}, { word: "live", tip: "/laÉªv/ ç¾å ´çš„ (adj)"},
                { word: "read", tip: "/riËd/ é–±è®€ (v ç¾åœ¨å¼)"}, { word: "read", tip: "/rÉ›d/ é–±è®€ (v éå»å¼)"},
                { word: "lead", tip: "/liËd/ å¼•å° (v)"}, { word: "lead", tip: "/lÉ›d/ é‰› (n)"},
                { word: "lose", tip: "/luËz/ å¤±å» (v)" }, { word: "loose", tip: "/luËs/ é¬†çš„ (adj)"},
                { word: "principal", tip: "æ ¡é•·ï¼›ä¸»è¦çš„" }, { word: "principle", tip: "åŸå‰‡ï¼›åŸç†" },
                { word: "quiet", tip: "å®‰éœçš„" }, { word: "quite", tip: "ç›¸ç•¶ï¼›é —" },
                { word: "allowed", tip: "å…è¨±" }, { word: "aloud", tip: "å¤§è²åœ°" },
            ];

            function populateExampleWords() {
                wordListButtonsDiv.innerHTML = ''; // Clear existing buttons
                exampleWords.forEach(item => {
                    const button = document.createElement('button');
                    button.textContent = `${item.word} (${item.tip})`;
                    button.className = 'word-button bg-gray-200 hover:bg-sky-200 text-gray-700 text-xs sm:text-sm py-1.5 px-3 rounded-full shadow-sm hover:shadow-md';
                    button.title = `ç·´ç¿’ç™¼éŸ³: ${item.word}`;
                    button.addEventListener('click', () => {
                        targetWordInput.value = item.word;
                        currentTargetWord = item.word.toLowerCase();
                        feedbackDiv.innerHTML = '';
                        feedbackDiv.className = 'feedback p-3 rounded-md text-base border border-transparent';
                        recognitionResultP.textContent = '';
                        if (speechSynthesis) speak(currentTargetWord);
                    });
                    wordListButtonsDiv.appendChild(button);
                });
            }
            
            function speak(text, lang = 'en-US', onEndCallback = null) {
                if (!speechSynthesis || !text) return;
                speechSynthesis.cancel(); // Cancel any previous speech

                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = lang;
                utterance.rate = 0.85; // Slightly slower for clarity
                utterance.pitch = 1.0;

                // Very basic phonetic distinction attempt for known homographs - often TTS dependent
                if (text === "read" && currentTargetWord === "read") { // If user picked from examples that might be past-tense
                    // This is a heuristic. If the *input field* value is "read", we can't know which one.
                    // If exampleWords contains "read" (/rÉ›d/), we could try to hint the TTS, but standard API has no direct phonetic input.
                    // Some TTS engines might interpret "I read that book yesterday" correctly.
                }


                if (onEndCallback && typeof onEndCallback === 'function') {
                    utterance.onend = onEndCallback;
                }
                speechSynthesis.speak(utterance);
            }

            if (playTargetWordButton) {
                playTargetWordButton.addEventListener('click', () => {
                    currentTargetWord = targetWordInput.value.trim().toLowerCase();
                    if (currentTargetWord && speechSynthesis) {
                        speak(currentTargetWord);
                    } else if (!currentTargetWord) {
                        feedbackDiv.innerHTML = '<p class="text-yellow-600 bg-yellow-100 border-yellow-500 border p-2 rounded-md">è«‹å…ˆè¼¸å…¥ç›®æ¨™å–®å­—ã€‚</p>';
                        feedbackDiv.className = 'feedback p-3 rounded-md text-base border-yellow-500 bg-yellow-100';
                    }
                });
            }

            // Function to clear existing audio player
            function clearAudioPlayer() {
                if (audioPlayerContainer) {
                    audioPlayerContainer.innerHTML = '';
                }
                audioBlob = null;
                audioChunks = [];
                recognizeAudioButton.classList.add('hidden'); // Hide recognize button
            }

            // Function to create and display audio player
            function createAudioPlayer(blob) {
                clearAudioPlayer(); 
                if (!blob || blob.size === 0) return;

                audioBlob = blob; 

                const audioElement = document.createElement('audio');
                audioElement.controls = true; // Use standard HTML5 controls
                audioElement.src = URL.createObjectURL(blob);
                audioElement.classList.add('w-full', 'mt-2');

                // const replayButton = document.createElement('button'); ... This custom button is no longer primary for playback
                
                audioPlayerContainer.appendChild(audioElement);
                recognizeAudioButton.classList.remove('hidden'); // Show recognize button
            }


            // === èªéŸ³è¾¨è­˜èˆ‡å€’æ•¸ (Web Speech API) === // This section will be heavily refactored
            // async function startSpeechRecognitionWithCountdown() { ... }
            // function stopSpeechRecognition() { ... }

            // Placeholder for new recording and Azure SDK functions
            async function startRecording() {
                // Implementation to come: uses MediaRecorder
                if (isRecognizing) return; // Rename isRecognizing to something like isBusy
                clearAudioPlayer();
                recognitionResultP.textContent = '';
                feedbackDiv.innerHTML = '';
                feedbackDiv.className = 'feedback p-3 rounded-md text-base border border-transparent';

                if (AZURE_SPEECH_KEY === "YOUR_AZURE_SPEECH_KEY" || AZURE_SPEECH_REGION === "YOUR_AZURE_REGION") {
                    feedbackDiv.innerHTML = '<p class="text-orange-600 bg-orange-100 border-orange-500 border p-3 rounded-md mb-4">è«‹åœ¨ç¨‹å¼ç¢¼ä¸­è¨­å®šæ‚¨çš„ Azure Speech Service é‡‘é‘°èˆ‡å€åŸŸæ‰èƒ½ä½¿ç”¨è¾¨è­˜åŠŸèƒ½ã€‚</p>';
                    feedbackDiv.className = 'feedback p-3 rounded-md text-base border-orange-500 bg-orange-100';
                    // return; // Decided not to return to allow recording even if keys are not set. Recognition will fail later.
                }


                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    isRecognizing = true; // Indicates recording is active

                    mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/wav' }); // Try WAV
                    audioChunks = [];

                    mediaRecorder.ondataavailable = event => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                        }
                    };

                    mediaRecorder.onstop = () => {
                        const completeAudioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        if (completeAudioBlob.size > 0) {
                            createAudioPlayer(completeAudioBlob);
                        }
                        stream.getTracks().forEach(track => track.stop()); // Release microphone
                        isRecognizing = false;
                        startRecordingButton.classList.remove('hidden');
                        stopRecordingButton.classList.add('hidden');
                    };
                    
                    mediaRecorder.onerror = (event) => { // Handle MediaRecorder errors
                        console.error('MediaRecorder error:', event.error);
                        feedbackDiv.innerHTML = `<p class='text-red-700'>éŒ„éŸ³æ™‚ç™¼ç”ŸéŒ¯èª¤: ${event.error.name}. è«‹æª¢æŸ¥éº¥å…‹é¢¨æˆ–ç€è¦½å™¨è¨­å®šã€‚</p>`;
                        feedbackDiv.className = 'feedback p-3 rounded-md text-base border-red-500 bg-red-100';
                        isRecognizing = false;
                        stream.getTracks().forEach(track => track.stop());
                        startRecordingButton.classList.remove('hidden');
                        stopRecordingButton.classList.add('hidden');
                    };

                    mediaRecorder.start();
                    recognitionResultP.textContent = 'ğŸ¤ éŒ„éŸ³ä¸­...';
                    startRecordingButton.classList.add('hidden');
                    stopRecordingButton.classList.remove('hidden');

                } catch (err) {
                    console.error("Error starting recording:", err);
                    feedbackDiv.innerHTML = `<p class='text-red-700'>ç„¡æ³•å•Ÿå‹•éŒ„éŸ³ï¼š${err.message}ã€‚è«‹å…è¨±éº¥å…‹é¢¨å­˜å–ã€‚</p>`;
                    feedbackDiv.className = 'feedback p-3 rounded-md text-base border-red-500 bg-red-100';
                    isRecognizing = false; // Reset flag
                    startRecordingButton.classList.remove('hidden');
                    stopRecordingButton.classList.add('hidden');
                }
            }

            function stopRecording() {
                if (mediaRecorder && mediaRecorder.state === "recording") {
                    mediaRecorder.stop(); // This will trigger mediaRecorder.onstop
                }
                // Button state updates are handled in onstop and startRecording
            }
            
            // Helper function to convert Blob to File, needed for Azure SDK's fromWavFileInput
            function convertBlobToFile(blob, fileName) {
                return new File([blob], fileName, { type: blob.type || 'audio/wav', lastModified: Date.now() });
            }

            async function recognizeRecordedAudio() {
                if (!audioBlob || audioBlob.size === 0) {
                    feedbackDiv.innerHTML = '<p class="text-yellow-600 bg-yellow-100 border-yellow-500 border p-2 rounded-md">æ²’æœ‰å¯è¾¨è­˜çš„éŒ„éŸ³ã€‚</p>';
                    feedbackDiv.className = 'feedback p-3 rounded-md text-base border-yellow-500 bg-yellow-100';
                    return;
                }

                if (AZURE_SPEECH_KEY === "YOUR_AZURE_SPEECH_KEY" || AZURE_SPEECH_REGION === "YOUR_AZURE_REGION") {
                    feedbackDiv.innerHTML = '<p class="text-red-600 bg-red-100 border-red-500 border p-3 rounded-md mb-4">ç„¡æ³•é€²è¡Œè¾¨è­˜ï¼šè«‹åœ¨ç¨‹å¼ç¢¼ä¸­è¨­å®šæ‚¨çš„ Azure Speech Service é‡‘é‘°èˆ‡å€åŸŸã€‚</p>';
                    feedbackDiv.className = 'feedback p-3 rounded-md text-base border-red-500 bg-red-100';
                    return;
                }

                recognitionResultP.textContent = 'ğŸ“¡ æ­£åœ¨å‚³é€èˆ‡è¾¨è­˜ä¸­...';
                feedbackDiv.innerHTML = '';
                feedbackDiv.className = 'feedback p-3 rounded-md text-base border border-transparent';
                recognizeAudioButton.disabled = true;
                recognizeAudioButton.classList.add('opacity-50');

                const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(AZURE_SPEECH_KEY, AZURE_SPEECH_REGION);
                speechConfig.speechRecognitionLanguage = "en-US";
                
                // Optional: Configure for pronunciation assessment (can be added later if needed)
                // const pronunciationAssessmentConfig = new SpeechSDK.PronunciationAssessmentConfig(
                //     currentTargetWord, // Target word for assessment
                //     SpeechSDK.PronunciationAssessmentGradingSystem.HundredMark,
                //     SpeechSDK.PronunciationAssessmentGranularity.Phoneme,
                //     true // Enable miscue
                // );
                // pronunciationAssessmentConfig.applyTo(recognizer); // Apply before recognition starts

                const audioFile = convertBlobToFile(audioBlob, "userRecording.wav");
                const audioConfig = SpeechSDK.AudioConfig.fromWavFileInput(audioFile);
                const recognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);

                recognizer.recognizeOnceAsync(
                    result => {
                        let recognizedText = '';
                        let alternatives = [];

                        if (result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
                            recognizedText = result.text.trim().toLowerCase().replace(/\.$/, '');
                            recognitionResultP.textContent = `ä½ èªªçš„æ˜¯: "${recognizedText}" (Azure)`;
                            
                            // Attempt to get N-best list from properties if available
                            const jsonResult = result.properties.getProperty(SpeechSDK.PropertyId.SpeechServiceResponse_JsonResult);
                            if (jsonResult) {
                                try {
                                    const parsedJson = JSON.parse(jsonResult);
                                    if (parsedJson && parsedJson.NBest) {
                                        alternatives = parsedJson.NBest.map(item => ({
                                            Lexical: item.Lexical.toLowerCase().replace(/\.$/, ''),
                                            Confidence: item.Confidence 
                                        }));
                                    }
                                } catch (e) {
                                    console.error("Error parsing NBest JSON from Azure:", e);
                                }
                            }
                           handleRecognitionResult(recognizedText, alternatives); // Reuse existing handler for now
                        } else if (result.reason === SpeechSDK.ResultReason.NoMatch) {
                            recognitionResultP.textContent = 'ç„¡æ³•è¾¨è­˜æ‚¨çš„èªéŸ³ (Azure)';
                            feedbackDiv.innerHTML = `<p class='text-orange-700'>Azure Speech Service ç„¡æ³•è¾¨è­˜æ‚¨çš„èªéŸ³ã€‚è«‹å†è©¦ä¸€æ¬¡ï¼Œç¢ºä¿ç™¼éŸ³æ¸…æ™°ä¸”éº¥å…‹é¢¨é‹ä½œæ­£å¸¸ã€‚</p>`;
                            feedbackDiv.className = 'feedback p-3 rounded-md text-base border-orange-500 bg-orange-100';
                        } else if (result.reason === SpeechSDK.ResultReason.Canceled) {
                            const cancellation = SpeechSDK.CancellationDetails.fromResult(result);
                            recognitionResultP.textContent = `è¾¨è­˜å·²å–æ¶ˆ (Azure)`;
                            let errorMessage = `è¾¨è­˜å·²å–æ¶ˆã€‚åŸå› : ${SpeechSDK.CancellationReason[cancellation.reason]}`;
                            if (cancellation.reason === SpeechSDK.CancellationReason.Error) {
                                errorMessage += ` éŒ¯èª¤ç¢¼: ${cancellation.ErrorCode}, è©³ç´°è³‡è¨Š: ${cancellation.errorDetails}`;
                                console.error(`Azure Speech SDK Canceled. ErrorCode: ${cancellation.ErrorCode}, ErrorDetails: ${cancellation.errorDetails}`);
                            }
                            feedbackDiv.innerHTML = `<p class='text-red-700'>${errorMessage}</p>`;
                            feedbackDiv.className = 'feedback p-3 rounded-md text-base border-red-500 bg-red-100';
                        }
                        recognizer.close();
                        recognizeAudioButton.disabled = false;
                        recognizeAudioButton.classList.remove('opacity-50');
                    },
                    err => {
                        recognitionResultP.textContent = 'è¾¨è­˜æ™‚ç™¼ç”ŸéŒ¯èª¤ (Azure)';
                        feedbackDiv.innerHTML = `<p class='text-red-700'>Azure Speech SDK éŒ¯èª¤: ${err}</p>`;
                        feedbackDiv.className = 'feedback p-3 rounded-md text-base border-red-500 bg-red-100';
                        console.error("Azure Speech SDK Error:", err);
                        recognizer.close();
                        recognizeAudioButton.disabled = false;
                        recognizeAudioButton.classList.remove('opacity-50');
                    }
                );
            }


            function handleRecognitionResult(recognizedText, alternatives) {
                // alternatives: array of SpeechRecognitionAlternative-like objects if available
                // e.g., [{ Lexical: "text", Confidence: 0.9 }, ...]
                const target = currentTargetWord;
                let isCorrect = false;
                let nbestHasTarget = false;
                let nbestHtml = '';

                if (recognizedText === target) {
                    isCorrect = true;
                }
                
                // Process alternatives if present (Web Speech API might provide them)
                if (Array.isArray(alternatives) && alternatives.length > 0) {
                    // The first alternative (alternatives[0]) is usually the `recognizedText`.
                    // We check if any *other* alternative matches the target.
                    nbestHasTarget = alternatives.some((item, idx) => item.Lexical && item.Lexical === target && item.Lexical !== recognizedText);

                    if (alternatives.length > 1) { // Only show if there are actual alternatives to the primary one
                        nbestHtml = `<div class='mt-2'><div class='font-semibold text-gray-700 mb-1'>å…¶ä»–è¾¨è­˜å¯èƒ½ï¼š</div><ul class='list-disc pl-5'>`;
                        alternatives.forEach((item) => {
                            // Don't list the primary recognized text again if it's the first in alternatives
                            if (item.Lexical && item.Lexical.trim() !== '' && item.Lexical !== recognizedText) { 
                                nbestHtml += `<li>${item.Lexical} <span class='text-xs text-gray-500'>(ä¿¡å¿ƒåº¦: ${(item.Confidence*100).toFixed(0)}%)</span></li>`;
                            }
                        });
                        nbestHtml += '</ul></div>';
                        // If nbestHtml only contains the ul tags and no list items, clear it
                        if (!nbestHtml.includes('<li>')) {
                            nbestHtml = '';
                        }
                    }
                }

                // UI Display
                if (isCorrect) {
                    feedbackDiv.innerHTML = `<p class="text-green-700 font-semibold">å¤ªæ£’äº†ï¼ç™¼éŸ³æ­£ç¢ºï¼ <span class="text-2xl">âœ…</span></p>`;
                    feedbackDiv.className = 'feedback p-3 rounded-md text-base border-green-500 bg-green-100';
                } else if (nbestHasTarget) {
                    feedbackDiv.innerHTML = `${nbestHtml}<p class="text-green-700 font-semibold mt-2">å¤ªæ£’äº†ï¼ç™¼éŸ³æ­£ç¢ºï¼ï¼ˆåœ¨å€™é¸ä¸­æ‰¾åˆ°ï¼‰<span class="text-2xl">âœ…</span></p>`;
                    feedbackDiv.className = 'feedback p-3 rounded-md text-base border-green-500 bg-green-100';
                } else {
                    feedbackDiv.innerHTML = `${nbestHtml}<p class="text-red-700 font-semibold mt-2">ç™¼éŸ³ä¸æ­£ç¢º <span class="text-2xl">âŒ</span></p>`;
                    if (recognizedText && recognizedText !== '') { // Add recognized text to feedback if it's not empty
                        feedbackDiv.innerHTML = `<p class="text-red-700 font-semibold">æ‚¨èªªçš„å¯èƒ½æ˜¯ï¼šã€Œ${recognizedText}ã€<span class="text-2xl ml-2">âŒ</span></p>` + nbestHtml;
                    } else if (!nbestHtml) { // If no recognized text and no alternatives, just show simple incorrect
                        feedbackDiv.innerHTML = `<p class="text-red-700 font-semibold mt-2">ç™¼éŸ³ä¸æ­£ç¢º <span class="text-2xl">âŒ</span></p>`;
                    }
                    feedbackDiv.className = 'feedback p-3 rounded-md text-base border-red-500 bg-red-100';
                }
            }

            // Bind buttons
            // startRecognitionButton.addEventListener('click', startSpeechRecognitionWithCountdown); // Old
            // stopRecognitionButton.addEventListener('click', stopSpeechRecognition); // Old
            startRecordingButton.addEventListener('click', startRecording);
            stopRecordingButton.addEventListener('click', stopRecording);
            recognizeAudioButton.addEventListener('click', recognizeRecordedAudio);


            populateExampleWords();
            if (targetWordInput.value) { // Initialize currentTargetWord from input field
                currentTargetWord = targetWordInput.value.trim().toLowerCase();
            }
        });
    </script>
</body>
</html> 