<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Azure Speech TTS with SSML</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        
        textarea {
            width: 100%;
            height: 200px;
            padding: 10px;
            font-family: monospace;
        }
        
        button {
            padding: 10px 15px;
            background-color: #0078d4;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
        }
        
        button:hover {
            background-color: #005a9e;
        }
        
        .controls {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
        }
        
        select, input {
            padding: 8px;
            border: 1px solid #ccc;
            border-radius: 4px;
        }
    </style>
</head>
<body>
    <h1>Azure Speech TTS with SSML</h1>
    
    <div class="container">
        <div>
            <h2>Azure Speech API Configuration</h2>
            <div class="controls">
                <input type="text" id="subscriptionKey" value="F3FER7g0BSWfiZTFWOXtW1tezbx9vnTgPE5MbeW1NVezZX4yKDFoJQQJ99BDACYeBjFXJ3w3AAAYACOGAQO2" />
                <input type="text" id="serviceRegion" value="eastus" />
            </div>
        </div>

        <div>
            <h2>SSML Input</h2>
            <textarea id="ssmlInput">
                <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="en-US">
                    <voice name="en-US-JennyNeural">
                        <prosody rate="0.8">
                            This is an example of <break time="300ms"/> Azure Text-to-Speech using SSML.
                        </prosody>
                        <mstts:express-as style="cheerful">
                            I can speak with different styles and emotions!
                        </mstts:express-as>
                    </voice>
                </speak>
            </textarea>
        </div>

        <div class="controls">
            <select id="voiceSelector">
                <option value="en-US-JennyNeural">English (US) - Jenny Neural</option>
                <option value="en-US-GuyNeural">English (US) - Guy Neural</option>
                <option value="zh-TW-HsiaoChenNeural">Chinese (Taiwan) - Hsiao Chen Neural</option>
                <option value="zh-TW-YunJheNeural">Chinese (Taiwan) - Yun Jhe Neural</option>
                <option value="zh-CN-XiaoxiaoNeural">Chinese (Mainland) - Xiaoxiao Neural</option>
                <option value="ja-JP-NanamiNeural">Japanese - Nanami Neural</option>
            </select>
            <button id="updateVoice">Update Voice in SSML</button>
            <button id="speakButton">Speak with SSML</button>
        </div>
        <hr>
        <div>
            <h2>Combined Audio (Male + Female Voice)</h2>
            <div class="controls">
                <input type="text" id="wordInput" placeholder="Enter word for combined audio" style="width: calc(50% - 5px); margin-right: 10px;"/>
                <input type="text" id="phoneticInput" placeholder="IPA for word (e.g., pɹəˈzɛnt)" style="width: calc(50% - 5px);"/>
            </div>
            <div class="controls" style="margin-top: 10px;">
                 <input type="text" id="sentenceInput" placeholder="Enter sentence for combined audio" style="width: 100%;"/>
            </div>
            <div class="controls" style="margin-top: 10px;">
                <button id="speakCombinedButton">Speak Combined Audio</button>
            </div>
        </div>

        <div>
            <h2>Audio Output</h2>
            <audio id="audioOutput" controls></audio>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const subscriptionKeyInput = document.getElementById('subscriptionKey');
            const serviceRegionInput = document.getElementById('serviceRegion');
            const ssmlInput = document.getElementById('ssmlInput');
            const voiceSelector = document.getElementById('voiceSelector');
            const updateVoiceButton = document.getElementById('updateVoice');
            const speakButton = document.getElementById('speakButton');
            const audioOutput = document.getElementById('audioOutput');

            // New elements for combined audio
            const wordInput = document.getElementById('wordInput');
            const sentenceInput = document.getElementById('sentenceInput');
            const speakCombinedButton = document.getElementById('speakCombinedButton');
            const phoneticInput = document.getElementById('phoneticInput');

            const AZURE_MALE_VOICE = "en-US-ChristopherNeural";
            const AZURE_FEMALE_VOICE = "en-US-JennyNeural"; // Using JennyNeural as female, was NancyNeural in voiceExport but JennyNeural is already in the list.

            // Update voice in SSML when button is clicked
            updateVoiceButton.addEventListener('click', () => {
                const selectedVoice = voiceSelector.value;
                let ssmlText = ssmlInput.value;
                
                // Update the voice attribute in the SSML
                ssmlText = ssmlText.replace(/<voice name="[^"]*">/g, `<voice name="${selectedVoice}">`);
                ssmlInput.value = ssmlText;
            });

            // Call Azure TTS API with SSML for combined audio
            speakCombinedButton.addEventListener('click', async () => {
                const subscriptionKey = subscriptionKeyInput.value.trim();
                const serviceRegion = serviceRegionInput.value.trim();
                const wordText = wordInput.value.trim();
                const sentenceText = sentenceInput.value.trim();
                const phoneticText = phoneticInput.value.trim();

                if (!subscriptionKey || !serviceRegion) {
                    alert('Please enter your Azure Speech subscription key and service region.');
                    return;
                }
                if (!wordText && !sentenceText) {
                    alert('Please enter a word or a sentence for the combined audio.');
                    return;
                }

                // Construct SSML for combined audio
                // Break tags are now inside prosody tags, as per user feedback.
                // Phonetic input is used if provided for the word.

                let maleWordSpeechPart;
                let femaleWordSpeechPart;

                if (phoneticText) {
                    maleWordSpeechPart = `<phoneme alphabet="ipa" ph="${phoneticText}">${wordText || ""}</phoneme><break time="1000ms"/>`;
                    femaleWordSpeechPart = `<phoneme alphabet="ipa" ph="${phoneticText}">${wordText || ""}</phoneme><break time="1500ms"/>`;
                } else {
                    maleWordSpeechPart = `${wordText || ""}<break time="1000ms"/>`;
                    femaleWordSpeechPart = `${wordText || ""}<break time="1500ms"/>`;
                }

                const combinedSSML = `
<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="en-US">
    <voice name="${AZURE_MALE_VOICE}">
        <prosody rate="1.0">${maleWordSpeechPart}</prosody>
    </voice>
    <voice name="${AZURE_FEMALE_VOICE}">
        <prosody rate="1.0">${femaleWordSpeechPart}</prosody>
    </voice>
    <voice name="${AZURE_MALE_VOICE}">
        <prosody rate="1.0">${sentenceText || ""}<break time="1000ms"/></prosody>
    </voice>
    <voice name="${AZURE_FEMALE_VOICE}">
        <prosody rate="1.0">${sentenceText || ""}<break time="1500ms"/></prosody>
    </voice>
</speak>
                `.trim();

                // Optionally, display the generated SSML in the main textarea for user to see
                // ssmlInput.value = combinedSSML;

                try {
                    const response = await fetch(`https://${serviceRegion}.tts.speech.microsoft.com/cognitiveservices/v1`, {
                        method: 'POST',
                        headers: {
                            'Ocp-Apim-Subscription-Key': subscriptionKey,
                            'Content-Type': 'application/ssml+xml',
                            'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3'
                        },
                        body: combinedSSML
                    });

                    if (!response.ok) {
                        throw new Error(`HTTP error! Status: ${response.status}`);
                    }

                    const audioBlob = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioOutput.src = audioUrl;
                    audioOutput.play();

                } catch (error) {
                    console.error('Error calling Azure TTS API for combined audio:', error);
                    alert(`Error generating combined audio: ${error.message}`);
                }
            });

            // Call Azure TTS API with SSML
            speakButton.addEventListener('click', async () => {
                const subscriptionKey = subscriptionKeyInput.value.trim();
                const serviceRegion = serviceRegionInput.value.trim();
                const ssmlText = ssmlInput.value.trim();

                if (!subscriptionKey || !serviceRegion) {
                    alert('Please enter your Azure Speech subscription key and service region.');
                    return;
                }

                try {
                    // Make API request to Azure TTS
                    const response = await fetch(`https://${serviceRegion}.tts.speech.microsoft.com/cognitiveservices/v1`, {
                        method: 'POST',
                        headers: {
                            'Ocp-Apim-Subscription-Key': subscriptionKey,
                            'Content-Type': 'application/ssml+xml',
                            'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3'
                        },
                        body: ssmlText
                    });

                    if (!response.ok) {
                        throw new Error(`HTTP error! Status: ${response.status}`);
                    }

                    // Convert response to blob and create URL for audio element
                    const audioBlob = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioOutput.src = audioUrl;
                    audioOutput.play();

                } catch (error) {
                    console.error('Error calling Azure TTS API:', error);
                    alert(`Error: ${error.message}`);
                }
            });
        });
    </script>
</body>
</html>
